# ğŸ“Š Global Football Analytics
*A modular, endâ€‘toâ€‘end data engineering project built for learning, exploration, and fun.*

This project ingests football data from a public API, transforms it into a clean STAR schema, loads it into an analytical database, and prepares it for downstream analytics and visualizations. It follows modern dataâ€‘engineering patterns and emphasizes clarity, modularity, and reproducibility.

---

# ğŸš€ Project Architecture
The pipeline follows a clean, layered structure:
```text
Extract â†’ Transform â†’ Load â†’ Analytics
```
Each layer is isolated, testable, and reusable.

---

# ğŸ—‚ï¸ Folder Structure
```text
global-football-analytics/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/        # API extractors â†’ raw data
â”‚   â”œâ”€â”€ transform/      # STAR-schema transformations â†’ clean data
â”‚   â”œâ”€â”€ load/           # DuckDB Load Layer
â”‚   â””â”€â”€ analytics/      # (future) SQL queries, dashboards, notebooks
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Immutable API dumps (JSON, CSV)
â”‚   â”œâ”€â”€ processed/      # Optional intermediate outputs (currently empty)
â”‚   â”œâ”€â”€ clean/          # Final curated STAR-schema Parquet files
â”‚   â””â”€â”€ analytics.duckdb  # DuckDB analytical database (ignored by Git)
â”‚
â”œâ”€â”€ tests/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
---

# ğŸ§© Data Lake Zones

### ğŸ“ raw/
Contains the exact files extracted from the API.  
No cleaning, no renaming, no schema changes.  
This layer is **immutable**.

### ğŸ“ processed/
Optional intermediate zone.  
Useful for multiâ€‘step transformations or debugging.  
Currently empty â€” the pipeline goes directly from raw â†’ clean.

### ğŸ“ clean/
The **Gold Layer**.  
Contains the final, curated STARâ€‘schema tables:
- `dim_team.parquet`
- `dim_player.parquet`
- `dim_venue.parquet`
- `dim_league.parquet`
- `fact_match.parquet`
- `fact_team_season.parquet`
- `fact_player_season.parquet`

These files are committed to Git so the project is fully reproducible.

### analytics.duckdb
The analytical database created by the Load Layer.  
Not committed to Git (binary, large, and fully reproducible).

---

# ğŸ—ï¸ Extract Layer
Located in `src/extract/`.

Responsibilities:

- Connect to the football API  
- Download raw JSON files  
- Store them in `data/raw/`  
- Ensure idempotency (safe reâ€‘runs)

To run the extractors:
```python
python -m src.extract.pipeline_extract
```

---

# ğŸ”„ Transform Layer
Located in `src/transform/`.

Responsibilities:

- Read raw JSON files  
- Normalize and clean the data  
- Build a **STAR schema**  
- Write final Parquet files to `data/clean/`

To run the transforms:
```python
python -m src.transform.pipeline_transform
```

---

# ğŸ—„ï¸ Load Layer (DuckDB)
Located in `src/load/`.

Responsibilities:

- Create or open `data/analytics.duckdb`
- Load all Parquet files from `data/clean/`
- Create analytical tables inside DuckDB

Run the Load Layer:
```python
python -m src.load.pipeline_load
```
This will recreate the DuckDB database from the clean Parquet files.

---

# ğŸ“ˆ Analytics Layer (coming soon)
This layer will include:

- SQL queries for insights  
- DuckDB views  
- Jupyter notebooks  
- Visualizations and dashboards

---

# ğŸ§ª Reproducibility
Install dependencies:
```python
pip install -r requirements.txt
```

Rebuild the entire database:
```python
python -m src.load.pipeline_load
```

The DuckDB file is not committed to Git â€” it is fully reproducible from the Parquet files.

---

# ğŸ”’ Data Notes
- All data comes from a **public football API**  
- No personal or sensitive data is stored  
- Only Parquet files (clean layer) are committed  
- DuckDB is excluded via `.gitignore`

---

# ğŸ§­ Future Improvements
- Add analytics notebooks  
- Add dashboards (Power BI, DuckDB, or Python)  
- Add support for multiple leagues and seasons  
- Add incremental ingestion  
- Add unit tests and CI/CD
